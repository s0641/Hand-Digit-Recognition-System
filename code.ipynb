{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GOPAL GUPTA\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:172: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape (100, 28, 28)\n",
      "test data shape (100,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GOPAL GUPTA\\Anaconda3\\lib\\site-packages\\skimage\\feature\\_hog.py:119: skimage_deprecation: Default value of `block_norm`==`L1` is deprecated and will be changed to `L2-Hys` in v0.15\n",
      "  'be changed to `L2-Hys` in v0.15', skimage_deprecation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7878787878787878\n",
      "loading \"test_image.png for digit recognition\" ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GOPAL GUPTA\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:126: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.696969696969697\n",
      "loading \"test_image.png for digit recognition\" ...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "from scipy.misc.pilutil import imresize\n",
    "import cv2 #version 3.2.0\n",
    "from skimage.feature import hog\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "DIGIT_WIDTH = 10 \n",
    "DIGIT_HEIGHT = 20\n",
    "IMG_HEIGHT = 28\n",
    "IMG_WIDTH = 28\n",
    "CLASS_N = 10 # 0-9\n",
    "\n",
    "#This method splits the input training image into small cells (of a single digit) and uses these cells as training data.\n",
    "#The default training image (MNIST) is a 1000x1000 size image and each digit is of size 10x20. so we divide 1000/10 horizontally and 1000/20 vertically.\n",
    "def split2d(img, cell_size, flatten=True):\n",
    "    h, w = img.shape[:2]\n",
    "    sx, sy = cell_size\n",
    "    cells = [np.hsplit(row, w//sx) for row in np.vsplit(img, h//sy)]\n",
    "    cells = np.array(cells)\n",
    "    if flatten:\n",
    "        cells = cells.reshape(-1, sy, sx)\n",
    "    return cells\n",
    "\n",
    "def load_digits(fn):\n",
    "    print('loading \"%s for training\" ...' % fn)\n",
    "    digits_img = cv2.imread(fn, 0)\n",
    "    digits = split2d(digits_img, (DIGIT_WIDTH, DIGIT_HEIGHT))\n",
    "    resized_digits = []\n",
    "    for digit in digits:\n",
    "        resized_digits.append(imresize(digit,(IMG_WIDTH, IMG_HEIGHT)))\n",
    "    labels = np.repeat(np.arange(CLASS_N), len(digits)/CLASS_N)\n",
    "    return np.array(resized_digits), labels\n",
    "\n",
    "def pixels_to_hog_20(img_array):\n",
    "    hog_featuresData = []\n",
    "    for img in img_array:\n",
    "        fd = hog(img, \n",
    "                 orientations=10, \n",
    "                 pixels_per_cell=(5,5),\n",
    "                 cells_per_block=(1,1), \n",
    "                 visualise=False)\n",
    "        hog_featuresData.append(fd)\n",
    "    hog_features = np.array(hog_featuresData, 'float64')\n",
    "    return np.float32(hog_features)\n",
    "\n",
    "#define a custom model in a similar class wrapper with train and predict methods\n",
    "class KNN_MODEL():\n",
    "    def __init__(self, k = 3):\n",
    "        self.k = k\n",
    "        self.model = cv2.ml.KNearest_create()\n",
    "\n",
    "    def train(self, samples, responses):\n",
    "        self.model.train(samples, cv2.ml.ROW_SAMPLE, responses)\n",
    "\n",
    "    def predict(self, samples):\n",
    "        retval, results, neigh_resp, dists = self.model.findNearest(samples, self.k)\n",
    "        return results.ravel()\n",
    "\n",
    "class SVM_MODEL():\n",
    "    def __init__(self, num_feats, C = 1, gamma = 0.1):\n",
    "        self.model = cv2.ml.SVM_create()\n",
    "        self.model.setType(cv2.ml.SVM_C_SVC)\n",
    "        self.model.setKernel(cv2.ml.SVM_RBF) #SVM_LINEAR, SVM_RBF\n",
    "        self.model.setC(C)\n",
    "        self.model.setGamma(gamma)\n",
    "        self.features = num_feats\n",
    "\n",
    "    def train(self, samples, responses):\n",
    "        self.model.train(samples, cv2.ml.ROW_SAMPLE, responses)\n",
    "\n",
    "    def predict(self, samples):\n",
    "        results = self.model.predict(samples.reshape(-1,self.features))\n",
    "        return results[1].ravel()\n",
    "\n",
    "\n",
    "def get_digits(contours, hierarchy):\n",
    "    hierarchy = hierarchy[0]\n",
    "    bounding_rectangles = [cv2.boundingRect(ctr) for ctr in contours]   \n",
    "    final_bounding_rectangles = []\n",
    "    #find the most common heirarchy level - that is where our digits's bounding boxes are\n",
    "    u, indices = np.unique(hierarchy[:,-1], return_inverse=True)\n",
    "    most_common_heirarchy = u[np.argmax(np.bincount(indices))]\n",
    "    \n",
    "    for r,hr in zip(bounding_rectangles, hierarchy):\n",
    "        x,y,w,h = r\n",
    "        #this could vary depending on the image you are trying to predict\n",
    "        #we are trying to extract ONLY the rectangles with images in it (this is a very simple way to do it)\n",
    "        #we use heirarchy to extract only the boxes that are in the same global level - to avoid digits inside other digits\n",
    "        #ex: there could be a bounding box inside every 6,9,8 because of the loops in the number's appearence - we don't want that.\n",
    "        #read more about it here: https://docs.opencv.org/trunk/d9/d8b/tutorial_py_contours_hierarchy.html\n",
    "        if ((w*h)>250) and (10 <= w <= 200) and (10 <= h <= 200) and hr[3] == most_common_heirarchy: \n",
    "            final_bounding_rectangles.append(r)    \n",
    "\n",
    "    return final_bounding_rectangles\n",
    "\n",
    "\n",
    "def proc_user_img(img_file, model):\n",
    "    print('loading \"%s for digit recognition\" ...' % img_file)\n",
    "    im = cv2.imread(img_file)    \n",
    "    blank_image = np.zeros((im.shape[0],im.shape[1],3), np.uint8)\n",
    "    blank_image.fill(255)\n",
    "\n",
    "    imgray = cv2.cvtColor(im,cv2.COLOR_BGR2GRAY)\n",
    "    plt.imshow(imgray)\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    \n",
    "    ret,thresh = cv2.threshold(imgray,127,255,0)   \n",
    "    thresh = cv2.erode(thresh,kernel,iterations = 1)\n",
    "    thresh = cv2.dilate(thresh,kernel,iterations = 1)\n",
    "    thresh = cv2.erode(thresh,kernel,iterations = 1)\n",
    "    \n",
    "    _,contours,hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    digits_rectangles = get_digits(contours,hierarchy)  #rectangles of bounding the digits in user image\n",
    "    \n",
    "    for rect in digits_rectangles:\n",
    "        x,y,w,h = rect\n",
    "        cv2.rectangle(im,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "        im_digit = imgray[y:y+h,x:x+w]\n",
    "        im_digit = (255-im_digit)\n",
    "        im_digit = imresize(im_digit,(IMG_WIDTH ,IMG_HEIGHT))\n",
    "\n",
    "        hog_img_data = pixels_to_hog_20([im_digit])  \n",
    "        pred = model.predict(hog_img_data)\n",
    "        cv2.putText(im, str(int(pred[0])), (x,y),cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 0, 0), 3)\n",
    "        cv2.putText(blank_image, str(int(pred[0])), (x,y),cv2.FONT_HERSHEY_SIMPLEX, 3, (255, 0, 0), 5)\n",
    "\n",
    "    plt.imshow(im)\n",
    "    cv2.imwrite(\"original_overlay.png\",im) \n",
    "    cv2.imwrite(\"final_digits.png\",blank_image) \n",
    "    cv2.destroyAllWindows()           \n",
    "\n",
    "\n",
    "def get_contour_precedence(contour, cols):\n",
    "    return contour[1] * cols + contour[0]  #row-wise ordering\n",
    "\n",
    "\n",
    "#this function processes a custom training image\n",
    "#see example : custom_train.digits.jpg\n",
    "#if you want to use your own, it should be in a similar format\n",
    "def load_digits_custom(img_file):\n",
    "    train_data = []\n",
    "    train_target = []\n",
    "    start_class = 1\n",
    "    im = cv2.imread(img_file)\n",
    "    imgray = cv2.cvtColor(im,cv2.COLOR_BGR2GRAY)\n",
    "    plt.imshow(imgray)\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    \n",
    "    ret,thresh = cv2.threshold(imgray,127,255,0)   \n",
    "    thresh = cv2.erode(thresh,kernel,iterations = 1)\n",
    "    thresh = cv2.dilate(thresh,kernel,iterations = 1)\n",
    "    thresh = cv2.erode(thresh,kernel,iterations = 1)\n",
    "    \n",
    "    _,contours,hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    digits_rectangles = get_digits(contours,hierarchy)  #rectangles of bounding the digits in user image\n",
    "    \n",
    "    #sort rectangles accoring to x,y pos so that we can label them\n",
    "    digits_rectangles.sort(key=lambda x:get_contour_precedence(x, im.shape[1]))\n",
    "    \n",
    "    for index,rect in enumerate(digits_rectangles):\n",
    "        x,y,w,h = rect\n",
    "        cv2.rectangle(im,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "        im_digit = imgray[y:y+h,x:x+w]\n",
    "        im_digit = (255-im_digit)\n",
    "        \n",
    "        im_digit = imresize(im_digit,(IMG_WIDTH, IMG_HEIGHT))\n",
    "        train_data.append(im_digit)\n",
    "        train_target.append(start_class%10)\n",
    "\n",
    "        if index>0 and (index+1) % 10 == 0:\n",
    "            start_class += 1\n",
    "    cv2.imwrite(\"training_box_overlay.png\",im)\n",
    "    \n",
    "    return np.array(train_data), np.array(train_target)\n",
    "\n",
    "#------------------data preparation--------------------------------------------\n",
    "\n",
    "TRAIN_MNIST_IMG = 'digits.png' \n",
    "TRAIN_USER_IMG = 'custom_train_digits.jpg'\n",
    "TEST_USER_IMG = 'test_image.png'\n",
    "\n",
    "#digits, labels = load_digits(TRAIN_MNIST_IMG) #original MNIST data (not good detection)\n",
    "digits, labels = load_digits_custom(TRAIN_USER_IMG) #my handwritten dataset (better than MNIST on my handwritten digits)\n",
    "\n",
    "print('train data shape',digits.shape)\n",
    "print('test data shape',labels.shape)\n",
    "\n",
    "digits, labels = shuffle(digits, labels, random_state=256)\n",
    "train_digits_data = pixels_to_hog_20(digits)\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_digits_data, labels, test_size=0.33, random_state=42)\n",
    "\n",
    "#------------------training and testing----------------------------------------\n",
    "\n",
    "model = KNN_MODEL(k = 3)\n",
    "model.train(X_train, y_train)\n",
    "preds = model.predict(X_test)\n",
    "print('Accuracy: ',accuracy_score(y_test, preds))\n",
    "\n",
    "model = KNN_MODEL(k = 4)\n",
    "model.train(train_digits_data, labels)\n",
    "proc_user_img(TEST_USER_IMG, model)\n",
    "\n",
    "\n",
    "\n",
    "model = SVM_MODEL(num_feats = train_digits_data.shape[1])\n",
    "model.train(X_train, y_train)\n",
    "preds = model.predict(X_test)\n",
    "print('Accuracy: ',accuracy_score(y_test, preds))\n",
    "\n",
    "model = SVM_MODEL(num_feats = train_digits_data.shape[1])\n",
    "model.train(train_digits_data, labels)\n",
    "proc_user_img(TEST_USER_IMG, model)\n",
    "\n",
    "#------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
